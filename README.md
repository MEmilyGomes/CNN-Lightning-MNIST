<div align="center">
  <img src="https://github.com/user-attachments/assets/ccb6f5f1-0e07-4eb2-aa7c-5f681c57a59c" alt="Descri√ß√£o da imagem" width="1000"/>
</div>

<h1 align="center">Redes Neurais Convolucionais (CNN) üì∏:</h1>

<h3 align="center">Classificando imagens do dataset MNIST com o m√≥dulo Lightning</h3>

<p align="center"><strong>Autores:</strong> Maria Emily Nayla Gomes da Silva e Yasmin Barbosa Shimizu</p>
<p align="center"><strong>Orientador:</strong> Prof. Dr. Daniel R. Cassar</p>

<p align="center">
<img loading="lazy" src="http://img.shields.io/static/v1?label=STATUS&message=EM%20DESENVOLVIMENTO&color=GREEN&style=for-the-badge"/>
</p>

## üìù Descri√ß√£o
<p align="justify"> O trabalho apresenta a constru√ß√£o de uma Rede Neural Convolucional (CNN) utilizando dados do dataset MNIST, o qual cont√©m in√∫meros tensores de imagens em preto e branco, acompanhados de seus respectivos r√≥tulos (labels) representando os d√≠gitos. A partir de um c√≥digo de refer√™ncia [adicionar], foram realizadas modifica√ß√µes para torn√°-lo compat√≠vel com a biblioteca Lightning, permitindo a obten√ß√£o de um modelo otimizado para a identifica√ß√£o de n√∫meros manuscritos. Para avaliar a qualidade do modelo, tamb√©m foi gerada uma matriz de confus√£o.</p>

## üìî Notebooks e arquivos do projeto
* `Imagens`: Pasta contento figuras utilizadas no README e o c√≥digo para gerar a imagem de visualiza√ß√£o do *dataset*.
  - `24Imagens_MNIST.png`: imagem de visua√ßiza√ß√£o do *dataset*.
  - `Construcao-Figura-24Imagens_MNIST.ipynb`: c√≥digo para gerar a imagem de visualiza√ß√£o do *dataset*.
  - `Matriz de Confus√£o - MNIST.png`: previs√£o obtida pela rede treinada.
  - `logos_ilum_cnpem_mcti_mec.jpg`: logotipos da institu√ß√£o na qual tal projeto foi realizado e seus v√≠nculos.
* `CNN.ipynb`: caderno principal do projeto, com o *download* do *dataset* MNIST, al√©m de constru√ß√£o, treinamento, teste e resultados obtidos com a CNN.
* `README.md`: descri√ß√£o geral do projeto.
  
## üóÇÔ∏è MNIST - Dataset
<p align="justify">O dataset escolhido para desenvolver uma CNN com a biblioteca Lightning foi o MNIST. Esse conjunto de dados apresenta um extenso banco com 60.000 exemplos para treinamento, al√©m de 10.000 exemplos previamente separados para teste. Dessa forma, trata-se de um conjunto vantajoso tanto para o treinamento quanto para a avalia√ß√£o da performance do modelo treinado. A seguir, apresenta-se uma imagem com 24 exemplos dispon√≠veis, cada um composto por um tensor da imagem e seu respectivo r√≥tulo, que representa o n√∫mero correspondente.</p>
<p> </p>
<div align="center">
  <img src="Imagens/24Imagens_MNIST.png" alt="Descri√ß√£o da imagem" width="1000"/>
</div>

## üèãÔ∏è‚Äç‚ôÄÔ∏è Construindo e Treinando a CNN
<p align="justify"> -> Biblioteca Lighting</p>
<p align="justify"> -> Cross Entropy</p>



## üî¢ Resultados Obtidos
<p align="justify">Os resultados obtidos foram excelentes. A baixa variabilidade dos dados, aliada ao grande n√∫mero de exemplos e ao uso de uma ferramenta otimizada, a biblioteca Lightning, justifica a matriz de confus√£o apresentada a seguir, bem como a acur√°cia superior a 98% alcan√ßada com apenas duas √©pocas. A concentra√ß√£o da densidade de predi√ß√µes na diagonal principal revela a qualidade do modelo, indicando que ele n√£o est√° sobreajustado, mas sim realizando uma grande quantidade de previs√µes corretas.</p>
<p> </p>
<div align="center">
  <img src="Imagens/Matriz de Confus√£o - MNIST.png" alt="Descri√ß√£o da imagem" width="500"/>
</div>


## üòÅ Conclus√£o
<p align="justify">A biblioteca Lightning mostrou-se bastante eficiente para lidar com os dados dispon√≠veis. Especificamente, trabalhamos com um grande volume de dados e com baixa variabilidade entre os exemplos. Ainda assim, apenas duas √©pocas de treinamento com tr√™s filtros foram suficientes para alcan√ßar uma acur√°cia superior a 98%. Dessa forma, consideramos essa ferramenta bastante poderosa.</p>

## üñáÔ∏è Informa√ß√µes t√©cnicas
* Linguagem de programa√ß√£o: `Python 3.9`
* Software:  `Jupyter Notebook`
* Bibliotecas e M√≥dulos: `Torch`, `Lightning`, `Typing`, `Scikit-learn`, `Seaborn`
<br>

## üë©‚Äçü¶≥ Refer√™ncias
$1$ [**Nicola, Nicholas Di. ‚Äúnicholas-dinicola/Lightning-Series"**](https://github.com/nicholas-dinicola/Lightning-Series)  
Acesso em 12 de abril de 2025. 

$2$ [**GeeksforGeeks. ‚ÄúMNIST Dataset‚ÄØ: Practical Applications Using Keras and PyTorch"**](https://www.geeksforgeeks.org/mnist-dataset/)  
Acesso em 12 de abril de 2025.


## üß† Contribui√ß√µes dos Colaboradores
| [<img loading="lazy" src="https://avatars.githubusercontent.com/u/172424897?v=4" width=115><br><sub> Maria Emily Nayla</sub>](https://github.com/MEmilyGomes)<br> [<sub>Ilum - CNPEM</sub>](https://ilum.cnpem.br/)<br> [<sub>Curr√≠culo Lattes</sub>](http://lattes.cnpq.br/9482558334105708)<br> | [<img loading="lazy" src="https://avatars.githubusercontent.com/u/171518829?v=4" width=115><br><sub>Yasmin Shimizu</sub>](https://github.com/yasminbshimizu)<br> [<sub>Ilum - CNPEM</sub>](https://ilum.cnpem.br/)<br> [<sub>Curr√≠culo Lattes</sub>](https://github.com/yasminbshimizu)<br> [<sub>Linkedin</sub>](https://www.linkedin.com/in/yasmin-bshimz/) | [<img loading="lazy" src="https://github.com/user-attachments/assets/463d4753-7fa4-4a42-aa54-409e4150bb51" width=115><br> <sub> Prof. Dr. Daniel R. Cassar </sub>](https://github.com/drcassar)<br> [<sub>Ilum - CNPEM</sub>](https://ilum.cnpem.br/)<br> [<sub>Curr√≠culo Lattes</sub>](http://lattes.cnpq.br/1717397276752482) | 
| :---: | :---: | :---: | 

#### Para o Projeto:
* Emily Gomes: Atualiza√ß√µes na constru√ß√£o, treinamento e an√°lise da previs√£o de uma CNN utilizando o Lightning.
* Yasmin Shimizu: Atualiza√ß√µes na constru√ß√£o, treinamento e an√°lise da previs√£o de uma CNN utilizando o Lightning.

#### Para o Reposit√≥rio GitHub:
* Emily Gomes: README e upload do notebook Jupyter referente a constru√ß√£o, treinamento e previs√£o da CNN.
* Yasmin Shimizu: README, upload de imagens e upload do notebook Jupyter referente √† figura "24Imagens_MNIST.png".


**Orienta√ß√£o e Revis√£o:** Prof. Dr. Daniel R. Cassar.
